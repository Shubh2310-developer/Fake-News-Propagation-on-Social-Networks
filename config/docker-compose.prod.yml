version: '3.8'

# Production Docker Compose Configuration for Fake News Game Theory
# =================================================================
#
# Production-ready configuration with:
# - High availability and scaling capabilities
# - Security hardening and resource limits
# - Production performance optimizations
# - Reverse proxy (Nginx) for load balancing
# - SSL/TLS termination
# - Monitoring and logging
# - Backup and disaster recovery considerations
#
# Usage:
#   docker-compose -f docker-compose.prod.yml up -d
#
# Additional services:
# - nginx: Reverse proxy and SSL termination
# - ml-service: Dedicated GPU-enabled ML service
# - worker: Celery workers for background tasks
# - prometheus: Metrics collection
# - grafana: Monitoring dashboard

services:
  # =======================
  # Nginx Reverse Proxy
  # =======================
  nginx:
    image: nginx:alpine
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      # Nginx configuration
      - ../config/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ../config/nginx/conf.d:/etc/nginx/conf.d:ro
      # SSL certificates (Let's Encrypt or custom)
      - ../config/ssl:/etc/nginx/ssl:ro
      # Static files serving
      - static_files:/var/www/static:ro
      - media_files:/var/www/media:ro
    depends_on:
      - frontend
      - backend
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 5s
      retries: 3
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /var/cache/nginx
      - /var/run

  # =======================
  # Frontend Service (Production)
  # =======================
  frontend:
    build:
      context: ../frontend
      dockerfile: Dockerfile.prod
      args:
        - NODE_ENV=production
        - BUILD_DATE=${BUILD_DATE:-unknown}
        - VCS_REF=${VCS_REF:-unknown}
    restart: unless-stopped
    environment:
      - NEXT_PUBLIC_API_URL=https://${DOMAIN:-localhost}/api
      - NEXT_PUBLIC_WS_URL=wss://${DOMAIN:-localhost}/ws
      - NODE_ENV=production
      - PORT=3000
    volumes:
      - static_files:/app/.next/static
    expose:
      - "3000"
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp

  # =======================
  # Backend Service (Production)
  # =======================
  backend:
    build:
      context: ../backend
      dockerfile: Dockerfile.prod
      args:
        - BUILD_DATE=${BUILD_DATE:-unknown}
        - VCS_REF=${VCS_REF:-unknown}
    restart: unless-stopped
    environment:
      # Database connection (use secrets in production)
      - DATABASE_URL=postgresql://${DB_USER:-postgres}:${DB_PASSWORD}@db:5432/${DB_NAME:-fakenews_prod}
      # Redis connection
      - REDIS_URL=redis://redis:6379/0
      # Security settings
      - SECRET_KEY=${SECRET_KEY}
      - DEBUG=false
      - LOG_LEVEL=info
      - CORS_ORIGINS=https://${DOMAIN:-localhost}
      # Performance settings
      - WORKERS=4
      - MAX_REQUESTS=1000
      - MAX_REQUESTS_JITTER=100
      - TIMEOUT=30
      # ML Model settings
      - ML_MODEL_PATH=/app/models
      - HUGGINGFACE_CACHE_DIR=/app/cache/huggingface
      - ML_WORKERS=2
      # Game Theory settings
      - SIMULATION_WORKERS=8
      - MAX_SIMULATION_TIME=600
      - CELERY_BROKER_URL=redis://redis:6379/1
      - CELERY_RESULT_BACKEND=redis://redis:6379/2
    volumes:
      - prod_ml_models:/app/models:ro
      - prod_hf_cache:/app/cache/huggingface:ro
      - media_files:/app/media
    expose:
      - "8000"
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    security_opt:
      - no-new-privileges:true

  # =======================
  # ML Service (GPU-enabled)
  # =======================
  ml-service:
    build:
      context: ../backend
      dockerfile: Dockerfile.ml
    restart: unless-stopped
    runtime: nvidia  # Requires nvidia-docker
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - ML_MODEL_PATH=/app/models
      - HUGGINGFACE_CACHE_DIR=/app/cache/huggingface
      - REDIS_URL=redis://redis:6379/3
      - LOG_LEVEL=info
    volumes:
      - prod_ml_models:/app/models:ro
      - prod_hf_cache:/app/cache/huggingface
    expose:
      - "8002"
    depends_on:
      - redis
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G
      placement:
        constraints:
          - node.labels.gpu==true
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 120s

  # =======================
  # Background Workers (Celery)
  # =======================
  worker:
    build:
      context: ../backend
      dockerfile: Dockerfile.prod
    restart: unless-stopped
    environment:
      - DATABASE_URL=postgresql://${DB_USER:-postgres}:${DB_PASSWORD}@db:5432/${DB_NAME:-fakenews_prod}
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/1
      - CELERY_RESULT_BACKEND=redis://redis:6379/2
      - SECRET_KEY=${SECRET_KEY}
      - LOG_LEVEL=info
      - ML_SERVICE_URL=http://ml-service:8002
    volumes:
      - prod_ml_models:/app/models:ro
      - media_files:/app/media
    depends_on:
      - db
      - redis
      - ml-service
    command: celery -A app.celery worker --loglevel=info --concurrency=4
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1.5'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    healthcheck:
      test: ["CMD", "celery", "-A", "app.celery", "inspect", "ping"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 60s

  # =======================
  # Database Service (Production)
  # =======================
  db:
    image: postgres:15-alpine
    restart: unless-stopped
    environment:
      - POSTGRES_USER=${DB_USER:-postgres}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_DB=${DB_NAME:-fakenews_prod}
      # Production performance tuning
      - POSTGRES_SHARED_PRELOAD_LIBRARIES=pg_stat_statements
      - POSTGRES_MAX_CONNECTIONS=200
      - POSTGRES_SHARED_BUFFERS=256MB
      - POSTGRES_EFFECTIVE_CACHE_SIZE=1GB
    volumes:
      - prod_postgres_data:/var/lib/postgresql/data
      - ../config/database/postgresql.prod.conf:/etc/postgresql/postgresql.conf:ro
      - ../config/database/prod_init.sql:/docker-entrypoint-initdb.d/01-init.sql:ro
    command: >
      postgres
      -c config_file=/etc/postgresql/postgresql.conf
      -c log_statement=ddl
      -c log_min_duration_statement=1000
      -c log_checkpoints=on
      -c log_connections=on
      -c log_disconnections=on
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-postgres} -d ${DB_NAME:-fakenews_prod}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    security_opt:
      - no-new-privileges:true

  # =======================
  # Redis Service (Production)
  # =======================
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    volumes:
      - prod_redis_data:/data
      - ../config/redis/redis.prod.conf:/usr/local/etc/redis/redis.conf:ro
    command: redis-server /usr/local/etc/redis/redis.conf
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 10s
    security_opt:
      - no-new-privileges:true

  # =======================
  # Monitoring Services
  # =======================

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    restart: unless-stopped
    volumes:
      - ../config/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ../config/prometheus/rules:/etc/prometheus/rules:ro
      - prod_prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    expose:
      - "9090"
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Grafana for monitoring dashboard
  grafana:
    image: grafana/grafana:latest
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    volumes:
      - prod_grafana_data:/var/lib/grafana
      - ../config/grafana/provisioning:/etc/grafana/provisioning:ro
      - ../config/grafana/dashboards:/var/lib/grafana/dashboards:ro
    expose:
      - "3001"
    depends_on:
      - prometheus

  # =======================
  # Backup Service
  # =======================
  backup:
    image: prodrigestivill/postgres-backup-local:latest
    restart: unless-stopped
    environment:
      - POSTGRES_HOST=db
      - POSTGRES_DB=${DB_NAME:-fakenews_prod}
      - POSTGRES_USER=${DB_USER:-postgres}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_EXTRA_OPTS=-Z9 --schema=public --blobs
      - SCHEDULE=@daily
      - BACKUP_KEEP_DAYS=7
      - BACKUP_KEEP_WEEKS=4
      - BACKUP_KEEP_MONTHS=6
    volumes:
      - prod_backups:/backups
    depends_on:
      - db

# =======================
# Production Volumes
# =======================
volumes:
  # Database persistent storage
  prod_postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/fake-news-game-theory/data/postgres

  # Redis persistent storage
  prod_redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/fake-news-game-theory/data/redis

  # ML models storage
  prod_ml_models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/fake-news-game-theory/data/models

  # Hugging Face cache
  prod_hf_cache:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/fake-news-game-theory/data/cache/huggingface

  # Static files (frontend assets)
  static_files:
    driver: local

  # Media files (uploads, generated content)
  media_files:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/fake-news-game-theory/data/media

  # Prometheus data
  prod_prometheus_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/fake-news-game-theory/data/prometheus

  # Grafana data
  prod_grafana_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/fake-news-game-theory/data/grafana

  # Database backups
  prod_backups:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/fake-news-game-theory/backups

# =======================
# Production Networks
# =======================
networks:
  default:
    name: fake-news-game-theory-prod-network
    driver: bridge
    driver_opts:
      com.docker.network.enable_ipv6: "true"
    ipam:
      driver: default
      config:
        - subnet: 172.22.0.0/16
        - subnet: 2001:db8:1::/64

# =======================
# Production Secrets (Docker Swarm)
# =======================
secrets:
  db_password:
    external: true
  secret_key:
    external: true
  ssl_cert:
    external: true
  ssl_key:
    external: true

# =======================
# Production Environment Requirements
# =======================
# Required environment variables:
# - DOMAIN: Domain name for the application
# - DB_USER: Database username
# - DB_PASSWORD: Database password (or use secrets)
# - DB_NAME: Database name
# - SECRET_KEY: Application secret key (or use secrets)
# - GRAFANA_ADMIN_PASSWORD: Grafana admin password
# - BUILD_DATE: Build timestamp
# - VCS_REF: Git commit hash
#
# Recommended system requirements:
# - CPU: 4+ cores per node
# - RAM: 16GB+ per node
# - Storage: SSD with 500GB+ available
# - GPU: NVIDIA GPU with 8GB+ VRAM for ML service
#
# Access URLs in production:
# - Main Application: https://your-domain.com
# - Admin Dashboard: https://your-domain.com/admin
# - API Documentation: https://your-domain.com/api/docs
# - Monitoring: https://your-domain.com/grafana (admin access)