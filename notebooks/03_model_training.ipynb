{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a98bb16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1164ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn imports\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    precision_recall_curve, roc_curve\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# transformers for BERT\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, DataCollatorWithPadding\n",
    ")\n",
    "\n",
    "# Additional imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import optuna  # for hyperparameter optimization\n",
    "import mlflow  # for experiment tracking\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f795e93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Pipeline Initialized\n",
      "Models will be saved to: /home/ghost/fake-news-game-theory/data/models\n",
      "Results will be saved to: /home/ghost/fake-news-game-theory/data/results\n"
     ]
    }
   ],
   "source": [
    "# Set up paths\n",
    "BASE_PATH = \"/home/ghost/fake-news-game-theory/data\"\n",
    "PROCESSED_PATH = os.path.join(BASE_PATH, \"processed\")\n",
    "MODELS_PATH = os.path.join(BASE_PATH, \"models\")\n",
    "RESULTS_PATH = os.path.join(BASE_PATH, \"results\")\n",
    "\n",
    "# Create directories\n",
    "for path in [MODELS_PATH, RESULTS_PATH]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "print(\"Model Training Pipeline Initialized\")\n",
    "print(f\"Models will be saved to: {MODELS_PATH}\")\n",
    "print(f\"Results will be saved to: {RESULTS_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8e6bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Data Loading and Preprocessing\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"Load and prepare data for model training\"\"\"\n",
    "    \n",
    "    def __init__(self, processed_path=PROCESSED_PATH):\n",
    "        self.processed_path = processed_path\n",
    "        self.scaler = None\n",
    "        self.feature_names = None\n",
    "        self.tfidf_vectorizer = None\n",
    "        \n",
    "    def load_training_data(self):\n",
    "        \"\"\"Load preprocessed training data\"\"\"\n",
    "        print(\"Loading training data...\")\n",
    "        \n",
    "        # Load features and labels\n",
    "        X_train = pd.read_csv(os.path.join(self.processed_path, 'train/X_train.csv'))\n",
    "        y_train = pd.read_csv(os.path.join(self.processed_path, 'train/y_train.csv'))\n",
    "        \n",
    "        X_val = pd.read_csv(os.path.join(self.processed_path, 'validation/X_val.csv'))\n",
    "        y_val = pd.read_csv(os.path.join(self.processed_path, 'validation/y_val.csv'))\n",
    "        \n",
    "        X_test = pd.read_csv(os.path.join(self.processed_path, 'test/X_test.csv'))\n",
    "        y_test = pd.read_csv(os.path.join(self.processed_path, 'test/y_test.csv'))\n",
    "        \n",
    "        # Load preprocessing objects\n",
    "        with open(os.path.join(self.processed_path, 'features/scaler.pkl'), 'rb') as f:\n",
    "            self.scaler = pickle.load(f)\n",
    "            \n",
    "        with open(os.path.join(self.processed_path, 'features/feature_names.pkl'), 'rb') as f:\n",
    "            self.feature_names = pickle.load(f)\n",
    "            \n",
    "        with open(os.path.join(self.processed_path, 'features/tfidf_vectorizer.pkl'), 'rb') as f:\n",
    "            self.tfidf_vectorizer = pickle.load(f)\n",
    "        \n",
    "        # Convert to numpy arrays and flatten labels\n",
    "        y_train = y_train.values.ravel()\n",
    "        y_val = y_val.values.ravel()\n",
    "        y_test = y_test.values.ravel()\n",
    "        \n",
    "        print(f\"Training set: {X_train.shape}\")\n",
    "        print(f\"Validation set: {X_val.shape}\")\n",
    "        print(f\"Test set: {X_test.shape}\")\n",
    "        print(f\"Features: {len(self.feature_names)}\")\n",
    "        \n",
    "        return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "    \n",
    "    def load_raw_text_data(self):\n",
    "        \"\"\"Load raw text data for BERT training\"\"\"\n",
    "        print(\"Loading raw text data for BERT...\")\n",
    "        \n",
    "        # Load the complete features file to get text\n",
    "        all_features = pd.read_csv(os.path.join(self.processed_path, 'features/all_features.csv'))\n",
    "        \n",
    "        # Extract text and labels\n",
    "        texts = all_features['text'].fillna('').astype(str).tolist()\n",
    "        labels = all_features['label'].values\n",
    "        \n",
    "        # Create train/val/test splits matching the feature splits\n",
    "        train_size = 3500\n",
    "        val_size = 500\n",
    "        test_size = 1000\n",
    "        \n",
    "        train_texts = texts[:train_size]\n",
    "        train_labels = labels[:train_size]\n",
    "        \n",
    "        val_texts = texts[train_size:train_size + val_size]\n",
    "        val_labels = labels[train_size:train_size + val_size]\n",
    "        \n",
    "        test_texts = texts[train_size + val_size:train_size + val_size + test_size]\n",
    "        test_labels = labels[train_size + val_size:train_size + val_size + test_size]\n",
    "        \n",
    "        print(f\"Text data loaded: {len(train_texts)} train, {len(val_texts)} val, {len(test_texts)} test\")\n",
    "        \n",
    "        return (train_texts, train_labels), (val_texts, val_labels), (test_texts, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb69a15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Traditional Machine Learning Models\n",
    "\n",
    "class TraditionalMLTrainer:\n",
    "    \"\"\"Train and evaluate traditional ML models\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        \n",
    "    def initialize_models(self):\n",
    "        \"\"\"Initialize baseline models\"\"\"\n",
    "        self.models = {\n",
    "            'logistic_regression': LogisticRegression(\n",
    "                random_state=42, max_iter=1000, class_weight='balanced'\n",
    "            ),\n",
    "            'random_forest': RandomForestClassifier(\n",
    "                n_estimators=100, random_state=42, class_weight='balanced'\n",
    "            ),\n",
    "            'gradient_boosting': GradientBoostingClassifier(\n",
    "                n_estimators=100, random_state=42\n",
    "            ),\n",
    "            'svm': SVC(\n",
    "                probability=True, random_state=42, class_weight='balanced'\n",
    "            ),\n",
    "            'naive_bayes': GaussianNB()\n",
    "        }\n",
    "        \n",
    "        print(f\"Initialized {len(self.models)} traditional ML models\")\n",
    "        \n",
    "    def train_baseline_models(self, X_train, y_train, X_val, y_val):\n",
    "        \"\"\"Train all baseline models\"\"\"\n",
    "        print(\"Training baseline models...\")\n",
    "        \n",
    "        trained_models = {}\n",
    "        \n",
    "        for name, model in tqdm(self.models.items(), desc=\"Training models\"):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Train model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            train_pred = model.predict(X_train)\n",
    "            val_pred = model.predict(X_val)\n",
    "            train_proba = model.predict_proba(X_train)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "            val_proba = model.predict_proba(X_val)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "            \n",
    "            # Calculate metrics\n",
    "            train_metrics = self._calculate_metrics(y_train, train_pred, train_proba)\n",
    "            val_metrics = self._calculate_metrics(y_val, val_pred, val_proba)\n",
    "            \n",
    "            training_time = time.time() - start_time\n",
    "            \n",
    "            # Store results\n",
    "            self.results[name] = {\n",
    "                'model': model,\n",
    "                'train_metrics': train_metrics,\n",
    "                'val_metrics': val_metrics,\n",
    "                'training_time': training_time\n",
    "            }\n",
    "            \n",
    "            trained_models[name] = model\n",
    "            \n",
    "            print(f\"{name}: Val Accuracy = {val_metrics['accuracy']:.4f}, \"\n",
    "                  f\"Val F1 = {val_metrics['f1']:.4f}, Time = {training_time:.2f}s\")\n",
    "        \n",
    "        return trained_models\n",
    "    \n",
    "    def hyperparameter_optimization(self, X_train, y_train, X_val, y_val):\n",
    "        \"\"\"Optimize hyperparameters for best models\"\"\"\n",
    "        print(\"Starting hyperparameter optimization...\")\n",
    "        \n",
    "        # Define parameter grids for top models\n",
    "        param_grids = {\n",
    "            'random_forest': {\n",
    "                'n_estimators': [100, 200, 300],\n",
    "                'max_depth': [10, 20, None],\n",
    "                'min_samples_split': [2, 5, 10],\n",
    "                'min_samples_leaf': [1, 2, 4],\n",
    "                'max_features': ['sqrt', 'log2']\n",
    "            },\n",
    "            'gradient_boosting': {\n",
    "                'n_estimators': [100, 200],\n",
    "                'learning_rate': [0.05, 0.1, 0.15],\n",
    "                'max_depth': [3, 5, 7],\n",
    "                'subsample': [0.8, 0.9, 1.0]\n",
    "            },\n",
    "            'logistic_regression': {\n",
    "                'C': [0.01, 0.1, 1, 10, 100],\n",
    "                'penalty': ['l1', 'l2'],\n",
    "                'solver': ['liblinear', 'saga']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        optimized_models = {}\n",
    "        \n",
    "        for model_name in ['random_forest', 'gradient_boosting', 'logistic_regression']:\n",
    "            print(f\"Optimizing {model_name}...\")\n",
    "            \n",
    "            base_model = self.models[model_name]\n",
    "            param_grid = param_grids[model_name]\n",
    "            \n",
    "            # Use RandomizedSearchCV for efficiency\n",
    "            search = RandomizedSearchCV(\n",
    "                base_model, \n",
    "                param_grid, \n",
    "                n_iter=20,  # Limit iterations for speed\n",
    "                cv=3,\n",
    "                scoring='f1',\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            search.fit(X_train, y_train)\n",
    "            \n",
    "            # Evaluate best model\n",
    "            best_model = search.best_estimator_\n",
    "            val_pred = best_model.predict(X_val)\n",
    "            val_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "            val_metrics = self._calculate_metrics(y_val, val_pred, val_proba)\n",
    "            \n",
    "            optimized_models[f\"{model_name}_optimized\"] = {\n",
    "                'model': best_model,\n",
    "                'best_params': search.best_params_,\n",
    "                'val_metrics': val_metrics,\n",
    "                'cv_score': search.best_score_\n",
    "            }\n",
    "            \n",
    "            print(f\"Best {model_name} - Val F1: {val_metrics['f1']:.4f}, \"\n",
    "                  f\"CV Score: {search.best_score_:.4f}\")\n",
    "        \n",
    "        return optimized_models\n",
    "    \n",
    "    def create_ensemble(self, models_dict, X_train, y_train, X_val, y_val):\n",
    "        \"\"\"Create ensemble of best models\"\"\"\n",
    "        print(\"Creating ensemble model...\")\n",
    "        \n",
    "        # Select top 3 models based on validation F1 score\n",
    "        model_scores = []\n",
    "        for name, result in self.results.items():\n",
    "            model_scores.append((name, result['val_metrics']['f1'], result['model']))\n",
    "        \n",
    "        model_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_models = model_scores[:3]\n",
    "        \n",
    "        print(\"Top models for ensemble:\")\n",
    "        for name, score, _ in top_models:\n",
    "            print(f\"  {name}: F1 = {score:.4f}\")\n",
    "        \n",
    "        # Create voting classifier\n",
    "        estimators = [(name, model) for name, _, model in top_models]\n",
    "        ensemble = VotingClassifier(estimators=estimators, voting='soft')\n",
    "        \n",
    "        # Train ensemble\n",
    "        ensemble.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate ensemble\n",
    "        val_pred = ensemble.predict(X_val)\n",
    "        val_proba = ensemble.predict_proba(X_val)[:, 1]\n",
    "        val_metrics = self._calculate_metrics(y_val, val_pred, val_proba)\n",
    "        \n",
    "        print(f\"Ensemble - Val Accuracy: {val_metrics['accuracy']:.4f}, \"\n",
    "              f\"Val F1: {val_metrics['f1']:.4f}\")\n",
    "        \n",
    "        return ensemble, val_metrics\n",
    "    \n",
    "    def _calculate_metrics(self, y_true, y_pred, y_proba=None):\n",
    "        \"\"\"Calculate comprehensive metrics\"\"\"\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_true, y_pred),\n",
    "            'precision': precision_score(y_true, y_pred, average='weighted'),\n",
    "            'recall': recall_score(y_true, y_pred, average='weighted'),\n",
    "            'f1': f1_score(y_true, y_pred, average='weighted')\n",
    "        }\n",
    "        \n",
    "        if y_proba is not None:\n",
    "            metrics['auc_roc'] = roc_auc_score(y_true, y_proba)\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2be8417",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Deep Learning Models\n",
    "\n",
    "class FakeNewsDataset(Dataset):\n",
    "    \"\"\"Dataset class for PyTorch training\"\"\"\n",
    "    \n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.FloatTensor(features.values if hasattr(features, 'values') else features)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "class DeepNeuralNetwork(nn.Module):\n",
    "    \"\"\"Deep neural network for fake news classification\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dims=[512, 256, 128], dropout_rate=0.3):\n",
    "        super(DeepNeuralNetwork, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(prev_dim, 2))  # 2 classes: fake, real\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class DeepLearningTrainer:\n",
    "    \"\"\"Train deep learning models\"\"\"\n",
    "    \n",
    "    def __init__(self, device=None):\n",
    "        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "    def train_neural_network(self, X_train, y_train, X_val, y_val, \n",
    "                           hidden_dims=[512, 256, 128], epochs=50, batch_size=64):\n",
    "        \"\"\"Train deep neural network\"\"\"\n",
    "        print(\"Training deep neural network...\")\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = FakeNewsDataset(X_train, y_train)\n",
    "        val_dataset = FakeNewsDataset(X_val, y_val)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # Initialize model\n",
    "        input_dim = X_train.shape[1]\n",
    "        model = DeepNeuralNetwork(input_dim, hidden_dims).to(self.device)\n",
    "        \n",
    "        # Loss and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "        \n",
    "        # Training loop\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        val_accuracies = []\n",
    "        \n",
    "        best_val_acc = 0\n",
    "        best_model_state = None\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for batch_features, batch_labels in train_loader:\n",
    "                batch_features, batch_labels = batch_features.to(self.device), batch_labels.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_features)\n",
    "                loss = criterion(outputs, batch_labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_features, batch_labels in val_loader:\n",
    "                    batch_features, batch_labels = batch_features.to(self.device), batch_labels.to(self.device)\n",
    "                    \n",
    "                    outputs = model(batch_features)\n",
    "                    loss = criterion(outputs, batch_labels)\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += batch_labels.size(0)\n",
    "                    correct += (predicted == batch_labels).sum().item()\n",
    "            \n",
    "            train_loss /= len(train_loader)\n",
    "            val_loss /= len(val_loader)\n",
    "            val_acc = correct / total\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            val_accuracies.append(val_acc)\n",
    "            \n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            # Save best model\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_model_state = model.state_dict().copy()\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch}/{epochs}: \"\n",
    "                      f\"Train Loss: {train_loss:.4f}, \"\n",
    "                      f\"Val Loss: {val_loss:.4f}, \"\n",
    "                      f\"Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        # Load best model\n",
    "        model.load_state_dict(best_model_state)\n",
    "        \n",
    "        # Final evaluation\n",
    "        final_metrics = self._evaluate_deep_model(model, val_loader)\n",
    "        \n",
    "        training_history = {\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'val_accuracies': val_accuracies,\n",
    "            'best_val_accuracy': best_val_acc\n",
    "        }\n",
    "        \n",
    "        return model, final_metrics, training_history\n",
    "    \n",
    "    def _evaluate_deep_model(self, model, data_loader):\n",
    "        \"\"\"Evaluate deep learning model\"\"\"\n",
    "        model.eval()\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        all_probabilities = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_features, batch_labels in data_loader:\n",
    "                batch_features, batch_labels = batch_features.to(self.device), batch_labels.to(self.device)\n",
    "                \n",
    "                outputs = model(batch_features)\n",
    "                probabilities = F.softmax(outputs, dim=1)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                \n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(batch_labels.cpu().numpy())\n",
    "                all_probabilities.extend(probabilities[:, 1].cpu().numpy())  # Probability of class 1\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(all_labels, all_predictions),\n",
    "            'precision': precision_score(all_labels, all_predictions, average='weighted'),\n",
    "            'recall': recall_score(all_labels, all_predictions, average='weighted'),\n",
    "            'f1': f1_score(all_labels, all_predictions, average='weighted'),\n",
    "            'auc_roc': roc_auc_score(all_labels, all_probabilities)\n",
    "        }\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7682d57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. BERT Training\n",
    "\n",
    "class BERTDataset(Dataset):\n",
    "    \"\"\"Dataset for BERT training\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "class BERTTrainer:\n",
    "    \"\"\"Train BERT model for fake news detection\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='bert-base-uncased'):\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = None\n",
    "        \n",
    "    def prepare_datasets(self, train_texts, train_labels, val_texts, val_labels, max_length=512):\n",
    "        \"\"\"Prepare datasets for BERT training\"\"\"\n",
    "        print(\"Preparing BERT datasets...\")\n",
    "        \n",
    "        train_dataset = BERTDataset(train_texts, train_labels, self.tokenizer, max_length)\n",
    "        val_dataset = BERTDataset(val_texts, val_labels, self.tokenizer, max_length)\n",
    "        \n",
    "        return train_dataset, val_dataset\n",
    "    \n",
    "    def train_bert(self, train_dataset, val_dataset, output_dir, epochs=3, batch_size=16):\n",
    "        \"\"\"Train BERT model\"\"\"\n",
    "        print(\"Training BERT model...\")\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            self.model_name,\n",
    "            num_labels=2\n",
    "        )\n",
    "        \n",
    "        # Training arguments\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            num_train_epochs=epochs,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            warmup_steps=500,\n",
    "            weight_decay=0.01,\n",
    "            logging_dir=f'{output_dir}/logs',\n",
    "            logging_steps=100,\n",
    "            evaluation_strategy=\"steps\",\n",
    "            eval_steps=500,\n",
    "            save_steps=1000,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"eval_f1\",\n",
    "            greater_is_better=True,\n",
    "            save_total_limit=2,\n",
    "            dataloader_num_workers=4\n",
    "        )\n",
    "        \n",
    "        # Initialize trainer\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "            compute_metrics=self._compute_metrics,\n",
    "            data_collator=DataCollatorWithPadding(tokenizer=self.tokenizer)\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        trainer.train()\n",
    "        \n",
    "        # Evaluate\n",
    "        eval_results = trainer.evaluate()\n",
    "        \n",
    "        return self.model, trainer, eval_results\n",
    "    \n",
    "    def _compute_metrics(self, eval_pred):\n",
    "        \"\"\"Compute metrics for BERT evaluation\"\"\"\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy_score(labels, predictions),\n",
    "            'f1': f1_score(labels, predictions, average='weighted'),\n",
    "            'precision': precision_score(labels, predictions, average='weighted'),\n",
    "            'recall': recall_score(labels, predictions, average='weighted')\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ae8740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Model Evaluation and Comparison\n",
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results = {}\n",
    "        \n",
    "    def evaluate_all_models(self, models_dict, X_test, y_test, text_test=None):\n",
    "        \"\"\"Evaluate all trained models on test set\"\"\"\n",
    "        print(\"Evaluating all models on test set...\")\n",
    "        \n",
    "        evaluation_results = {}\n",
    "        \n",
    "        for model_name, model_info in models_dict.items():\n",
    "            print(f\"Evaluating {model_name}...\")\n",
    "            \n",
    "            if model_name == 'bert' and text_test is not None:\n",
    "                # Special handling for BERT\n",
    "                metrics = self._evaluate_bert_model(model_info, text_test, y_test)\n",
    "            elif model_name == 'deep_nn':\n",
    "                # Special handling for deep neural network\n",
    "                metrics = self._evaluate_deep_model(model_info, X_test, y_test)\n",
    "            else:\n",
    "                # Traditional ML models\n",
    "                model = model_info['model'] if isinstance(model_info, dict) else model_info\n",
    "                metrics = self._evaluate_traditional_model(model, X_test, y_test)\n",
    "            \n",
    "            evaluation_results[model_name] = metrics\n",
    "            \n",
    "        return evaluation_results\n",
    "    \n",
    "    def _evaluate_traditional_model(self, model, X_test, y_test):\n",
    "        \"\"\"Evaluate traditional ML model\"\"\"\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "            'recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "            'f1': f1_score(y_test, y_pred, average='weighted'),\n",
    "            'confusion_matrix': confusion_matrix(y_test, y_pred).tolist()\n",
    "        }\n",
    "        \n",
    "        if y_proba is not None:\n",
    "            metrics['auc_roc'] = roc_auc_score(y_test, y_proba)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def _evaluate_deep_model(self, model_info, X_test, y_test):\n",
    "        \"\"\"Evaluate deep learning model\"\"\"\n",
    "        model = model_info['model']\n",
    "        model.eval()\n",
    "        \n",
    "        # Convert to tensors\n",
    "        X_test_tensor = torch.FloatTensor(X_test.values if hasattr(X_test, 'values') else X_test)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(X_test_tensor)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "        \n",
    "        y_pred = predictions.numpy()\n",
    "        y_proba = probabilities[:, 1].numpy()\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "            'recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "            'f1': f1_score(y_test, y_pred, average='weighted'),\n",
    "            'auc_roc': roc_auc_score(y_test, y_proba),\n",
    "            'confusion_matrix': confusion_matrix(y_test, y_pred).tolist()\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def _evaluate_bert_model(self, model_info, text_test, y_test):\n",
    "        \"\"\"Evaluate BERT model\"\"\"\n",
    "        tokenizer = model_info['tokenizer']\n",
    "        model = model_info['model']\n",
    "        \n",
    "        # Tokenize test texts\n",
    "        test_encodings = tokenizer(\n",
    "            text_test,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**test_encodings)\n",
    "            probabilities = F.softmax(outputs.logits, dim=1)\n",
    "            predictions = torch.argmax(outputs.logits, dim=1)\n",
    "        \n",
    "        y_pred = predictions.numpy()\n",
    "        y_proba = probabilities[:, 1].numpy()\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "            'recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "            'f1': f1_score(y_test, y_pred, average='weighted'),\n",
    "            'auc_roc': roc_auc_score(y_test, y_proba),\n",
    "            'confusion_matrix': confusion_matrix(y_test, y_pred).tolist()\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def create_comparison_report(self, results):\n",
    "        \"\"\"Create comprehensive comparison report\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"MODEL COMPARISON REPORT\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Create comparison dataframe\n",
    "        comparison_data = []\n",
    "        for model_name, metrics in results.items():\n",
    "            comparison_data.append({\n",
    "                'Model': model_name,\n",
    "                'Accuracy': metrics['accuracy'],\n",
    "                'Precision': metrics['precision'],\n",
    "                'Recall': metrics['recall'],\n",
    "                'F1 Score': metrics['f1'],\n",
    "                'AUC-ROC': metrics.get('auc_roc', 'N/A')\n",
    "            })\n",
    "        \n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        comparison_df = comparison_df.sort_values('F1 Score', ascending=False)\n",
    "        \n",
    "        print(comparison_df.to_string(index=False, float_format='%.4f'))\n",
    "        \n",
    "        # Identify best model\n",
    "        best_model = comparison_df.iloc[0]['Model']\n",
    "        best_f1 = comparison_df.iloc[0]['F1 Score']\n",
    "        \n",
    "        print(f\"\\nüèÜ Best Model: {best_model} (F1 Score: {best_f1:.4f})\")\n",
    "        \n",
    "        return comparison_df\n",
    "    \n",
    "    def plot_model_comparison(self, results, save_path=None):\n",
    "        \"\"\"Create visualization of model comparison\"\"\"\n",
    "        # Prepare data for plotting\n",
    "        models = list(results.keys())\n",
    "        metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        axes = axes.ravel()\n",
    "        \n",
    "        for i, metric in enumerate(metrics):\n",
    "            values = [results[model][metric] for model in models]\n",
    "            \n",
    "            bars = axes[i].bar(models, values, alpha=0.7, \n",
    "                              color=['skyblue', 'lightcoral', 'lightgreen', 'gold', 'plum'])\n",
    "            axes[i].set_title(f'{metric.capitalize()} Comparison', fontsize=14, fontweight='bold')\n",
    "            axes[i].set_ylabel(metric.capitalize())\n",
    "            axes[i].set_ylim([0, 1])\n",
    "            axes[i].tick_params(axis='x', rotation=45)\n",
    "            axes[i].grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                axes[i].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                           f'{height:.3f}',\n",
    "                           ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"Comparison plot saved to: {save_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    def plot_confusion_matrices(self, results, save_path=None):\n",
    "        \"\"\"Plot confusion matrices for all models\"\"\"\n",
    "        n_models = len(results)\n",
    "        fig, axes = plt.subplots(2, (n_models + 1) // 2, figsize=(15, 8))\n",
    "        axes = axes.ravel()\n",
    "        \n",
    "        for idx, (model_name, metrics) in enumerate(results.items()):\n",
    "            if 'confusion_matrix' in metrics:\n",
    "                cm = np.array(metrics['confusion_matrix'])\n",
    "                \n",
    "                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                           ax=axes[idx], cbar=True,\n",
    "                           xticklabels=['Fake', 'Real'],\n",
    "                           yticklabels=['Fake', 'Real'])\n",
    "                axes[idx].set_title(f'{model_name}\\nConfusion Matrix')\n",
    "                axes[idx].set_ylabel('True Label')\n",
    "                axes[idx].set_xlabel('Predicted Label')\n",
    "        \n",
    "        # Hide unused subplots\n",
    "        for idx in range(len(results), len(axes)):\n",
    "            axes[idx].set_visible(False)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"Confusion matrices saved to: {save_path}\")\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb33653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Model Persistence and Deployment\n",
    "\n",
    "class ModelManager:\n",
    "    \"\"\"Manage model saving, loading, and versioning\"\"\"\n",
    "    \n",
    "    def __init__(self, models_path=MODELS_PATH):\n",
    "        self.models_path = models_path\n",
    "        \n",
    "    def save_model(self, model, model_name, metrics=None, metadata=None):\n",
    "        \"\"\"Save trained model with metadata\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        model_dir = os.path.join(self.models_path, f\"{model_name}_{timestamp}\")\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        # Save model\n",
    "        model_file = os.path.join(model_dir, 'model.pkl')\n",
    "        \n",
    "        if isinstance(model, nn.Module):\n",
    "            # PyTorch model\n",
    "            torch.save(model.state_dict(), model_file.replace('.pkl', '.pth'))\n",
    "        else:\n",
    "            # Scikit-learn or traditional model\n",
    "            joblib.dump(model, model_file)\n",
    "        \n",
    "        # Save metrics\n",
    "        if metrics:\n",
    "            metrics_file = os.path.join(model_dir, 'metrics.json')\n",
    "            with open(metrics_file, 'w') as f:\n",
    "                json.dump(metrics, f, indent=2)\n",
    "        \n",
    "        # Save metadata\n",
    "        full_metadata = {\n",
    "            'model_name': model_name,\n",
    "            'timestamp': timestamp,\n",
    "            'model_type': type(model).__name__,\n",
    "            **(metadata or {})\n",
    "        }\n",
    "        \n",
    "        metadata_file = os.path.join(model_dir, 'metadata.json')\n",
    "        with open(metadata_file, 'w') as f:\n",
    "            json.dump(full_metadata, f, indent=2)\n",
    "        \n",
    "        print(f\"Model saved to: {model_dir}\")\n",
    "        return model_dir\n",
    "    \n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"Load saved model\"\"\"\n",
    "        # Check for PyTorch model\n",
    "        pth_file = os.path.join(model_path, 'model.pth')\n",
    "        pkl_file = os.path.join(model_path, 'model.pkl')\n",
    "        \n",
    "        if os.path.exists(pth_file):\n",
    "            # Load PyTorch model (need to reconstruct architecture)\n",
    "            print(\"Loading PyTorch model...\")\n",
    "            return torch.load(pth_file)\n",
    "        elif os.path.exists(pkl_file):\n",
    "            # Load traditional model\n",
    "            print(\"Loading traditional ML model...\")\n",
    "            return joblib.load(pkl_file)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"No model file found in {model_path}\")\n",
    "    \n",
    "    def save_best_model(self, models_dict, comparison_df, criteria='F1 Score'):\n",
    "        \"\"\"Save the best performing model\"\"\"\n",
    "        best_model_name = comparison_df.iloc[0]['Model']\n",
    "        best_model = models_dict[best_model_name]\n",
    "        \n",
    "        # Extract model object if wrapped in dict\n",
    "        if isinstance(best_model, dict):\n",
    "            model = best_model.get('model', best_model)\n",
    "            metrics = best_model.get('val_metrics', {})\n",
    "        else:\n",
    "            model = best_model\n",
    "            metrics = {}\n",
    "        \n",
    "        metadata = {\n",
    "            'selection_criteria': criteria,\n",
    "            'comparison_rank': 1,\n",
    "            'total_models_compared': len(models_dict)\n",
    "        }\n",
    "        \n",
    "        save_path = self.save_model(model, f\"best_{best_model_name}\", metrics, metadata)\n",
    "        \n",
    "        print(f\"\\nBest model ({best_model_name}) saved successfully!\")\n",
    "        return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e81c5b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Complete Training Pipeline\n",
    "\n",
    "class CompletePipeline:\n",
    "    \"\"\"Complete end-to-end training pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data_loader = DataLoader()\n",
    "        self.traditional_trainer = TraditionalMLTrainer()\n",
    "        self.deep_trainer = DeepLearningTrainer()\n",
    "        self.bert_trainer = BERTTrainer()\n",
    "        self.evaluator = ModelEvaluator()\n",
    "        self.model_manager = ModelManager()\n",
    "        \n",
    "        self.all_models = {}\n",
    "        self.results = {}\n",
    "        \n",
    "    def run_complete_pipeline(self, train_bert=False, train_deep_nn=True):\n",
    "        \"\"\"Run complete training pipeline\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"STARTING COMPLETE MODEL TRAINING PIPELINE\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "        \n",
    "        # Step 1: Load data\n",
    "        print(\"STEP 1: Loading Data\")\n",
    "        print(\"-\" * 70)\n",
    "        (X_train, y_train), (X_val, y_val), (X_test, y_test) = self.data_loader.load_training_data()\n",
    "        \n",
    "        # Step 2: Train traditional ML models\n",
    "        print(\"\\nSTEP 2: Training Traditional ML Models\")\n",
    "        print(\"-\" * 70)\n",
    "        self.traditional_trainer.initialize_models()\n",
    "        baseline_models = self.traditional_trainer.train_baseline_models(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "        self.all_models.update(baseline_models)\n",
    "        \n",
    "        # Step 3: Hyperparameter optimization\n",
    "        print(\"\\nSTEP 3: Hyperparameter Optimization\")\n",
    "        print(\"-\" * 70)\n",
    "        optimized_models = self.traditional_trainer.hyperparameter_optimization(\n",
    "            X_train, y_train, X_val, y_val\n",
    "        )\n",
    "        self.all_models.update({name: info['model'] for name, info in optimized_models.items()})\n",
    "        \n",
    "        # Step 4: Create ensemble\n",
    "        print(\"\\nSTEP 4: Creating Ensemble Model\")\n",
    "        print(\"-\" * 70)\n",
    "        ensemble_model, ensemble_metrics = self.traditional_trainer.create_ensemble(\n",
    "            self.all_models, X_train, y_train, X_val, y_val\n",
    "        )\n",
    "        self.all_models['ensemble'] = ensemble_model\n",
    "        \n",
    "        # Step 5: Train deep neural network\n",
    "        if train_deep_nn:\n",
    "            print(\"\\nSTEP 5: Training Deep Neural Network\")\n",
    "            print(\"-\" * 70)\n",
    "            dnn_model, dnn_metrics, dnn_history = self.deep_trainer.train_neural_network(\n",
    "                X_train, y_train, X_val, y_val\n",
    "            )\n",
    "            self.all_models['deep_nn'] = {'model': dnn_model, 'history': dnn_history}\n",
    "        \n",
    "        # Step 6: Train BERT (optional, resource-intensive)\n",
    "        if train_bert:\n",
    "            print(\"\\nSTEP 6: Training BERT Model\")\n",
    "            print(\"-\" * 70)\n",
    "            (train_texts, train_labels), (val_texts, val_labels), (test_texts, test_labels) = \\\n",
    "                self.data_loader.load_raw_text_data()\n",
    "            \n",
    "            train_dataset, val_dataset = self.bert_trainer.prepare_datasets(\n",
    "                train_texts, train_labels, val_texts, val_labels\n",
    "            )\n",
    "            \n",
    "            bert_output_dir = os.path.join(MODELS_PATH, 'bert_model')\n",
    "            bert_model, bert_trainer, bert_results = self.bert_trainer.train_bert(\n",
    "                train_dataset, val_dataset, bert_output_dir\n",
    "            )\n",
    "            \n",
    "            self.all_models['bert'] = {\n",
    "                'model': bert_model,\n",
    "                'tokenizer': self.bert_trainer.tokenizer,\n",
    "                'trainer': bert_trainer\n",
    "            }\n",
    "        \n",
    "        # Step 7: Evaluate all models\n",
    "        print(\"\\nSTEP 7: Evaluating All Models on Test Set\")\n",
    "        print(\"-\" * 70)\n",
    "        test_results = self.evaluator.evaluate_all_models(\n",
    "            self.all_models, X_test, y_test\n",
    "        )\n",
    "        \n",
    "        # Step 8: Create comparison report\n",
    "        print(\"\\nSTEP 8: Creating Comparison Report\")\n",
    "        print(\"-\" * 70)\n",
    "        comparison_df = self.evaluator.create_comparison_report(test_results)\n",
    "        \n",
    "        # Step 9: Save visualizations\n",
    "        print(\"\\nSTEP 9: Creating Visualizations\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        comparison_plot_path = os.path.join(RESULTS_PATH, 'model_comparison.png')\n",
    "        self.evaluator.plot_model_comparison(test_results, comparison_plot_path)\n",
    "        \n",
    "        confusion_matrix_path = os.path.join(RESULTS_PATH, 'confusion_matrices.png')\n",
    "        self.evaluator.plot_confusion_matrices(test_results, confusion_matrix_path)\n",
    "        \n",
    "        # Step 10: Save best model\n",
    "        print(\"\\nSTEP 10: Saving Best Model\")\n",
    "        print(\"-\" * 70)\n",
    "        best_model_path = self.model_manager.save_best_model(\n",
    "            self.all_models, comparison_df\n",
    "        )\n",
    "        \n",
    "        # Save comparison results\n",
    "        comparison_file = os.path.join(RESULTS_PATH, 'model_comparison.csv')\n",
    "        comparison_df.to_csv(comparison_file, index=False)\n",
    "        print(f\"Comparison results saved to: {comparison_file}\")\n",
    "        \n",
    "        # Final summary\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"PIPELINE COMPLETE!\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Total models trained: {len(self.all_models)}\")\n",
    "        print(f\"Best model: {comparison_df.iloc[0]['Model']}\")\n",
    "        print(f\"Best F1 Score: {comparison_df.iloc[0]['F1 Score']:.4f}\")\n",
    "        print(f\"Results saved to: {RESULTS_PATH}\")\n",
    "        print(f\"Models saved to: {MODELS_PATH}\")\n",
    "        \n",
    "        return {\n",
    "            'models': self.all_models,\n",
    "            'test_results': test_results,\n",
    "            'comparison': comparison_df,\n",
    "            'best_model_path': best_model_path\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a10f74b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8. Quick Training Script\n",
    "\n",
    "def quick_train():\n",
    "    \"\"\"Quick training script for immediate use\"\"\"\n",
    "    pipeline = CompletePipeline()\n",
    "    \n",
    "    # Run with default settings (no BERT for speed)\n",
    "    results = pipeline.run_complete_pipeline(\n",
    "        train_bert=False,  # Set to True if you have GPU and time\n",
    "        train_deep_nn=True\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "## 9. Individual Model Training Functions\n",
    "\n",
    "def train_single_model(model_type='random_forest'):\n",
    "    \"\"\"Train a single model quickly\"\"\"\n",
    "    print(f\"Training {model_type} model...\")\n",
    "    \n",
    "    # Load data\n",
    "    data_loader = DataLoader()\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = data_loader.load_training_data()\n",
    "    \n",
    "    # Initialize and train model\n",
    "    if model_type == 'random_forest':\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "    elif model_type == 'gradient_boosting':\n",
    "        model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "    elif model_type == 'logistic_regression':\n",
    "        model = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    val_pred = model.predict(X_val)\n",
    "    val_metrics = {\n",
    "        'accuracy': accuracy_score(y_val, val_pred),\n",
    "        'precision': precision_score(y_val, val_pred, average='weighted'),\n",
    "        'recall': recall_score(y_val, val_pred, average='weighted'),\n",
    "        'f1': f1_score(y_val, val_pred, average='weighted')\n",
    "    }\n",
    "    \n",
    "    print(f\"Validation Metrics:\")\n",
    "    for metric, value in val_metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    manager = ModelManager()\n",
    "    save_path = manager.save_model(model, model_type, val_metrics)\n",
    "    \n",
    "    return model, val_metrics, save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eab8489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FAKE NEWS DETECTION MODEL TRAINING\n",
      "======================================================================\n",
      "\n",
      "Available training options:\n",
      "\n",
      "1. Quick Training (Recommended):\n",
      "   results = quick_train()\n",
      "\n",
      "2. Complete Pipeline:\n",
      "   pipeline = CompletePipeline()\n",
      "   results = pipeline.run_complete_pipeline(train_bert=False, train_deep_nn=True)\n",
      "\n",
      "3. Single Model Training:\n",
      "   model, metrics, path = train_single_model('random_forest')\n",
      "\n",
      "4. Custom Training:\n",
      "   # Use individual trainer classes for custom workflows\n",
      "\n",
      "Starting quick training...\n",
      "======================================================================\n",
      "\n",
      "Using device: cuda\n",
      "\n",
      "======================================================================\n",
      "STARTING COMPLETE MODEL TRAINING PIPELINE\n",
      "======================================================================\n",
      "\n",
      "STEP 1: Loading Data\n",
      "----------------------------------------------------------------------\n",
      "Loading training data...\n",
      "Training set: (3500, 2031)\n",
      "Validation set: (500, 2031)\n",
      "Test set: (1000, 2031)\n",
      "Features: 2031\n",
      "\n",
      "STEP 2: Training Traditional ML Models\n",
      "----------------------------------------------------------------------\n",
      "Initialized 5 traditional ML models\n",
      "Training baseline models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  20%|‚ñà‚ñà        | 1/5 [00:00<00:03,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression: Val Accuracy = 0.7700, Val F1 = 0.7701, Time = 0.91s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:02<00:04,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest: Val Accuracy = 0.8380, Val F1 = 0.8307, Time = 1.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:10<00:08,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient_boosting: Val Accuracy = 0.8440, Val F1 = 0.8374, Time = 8.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [01:12<00:26, 26.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm: Val Accuracy = 0.8240, Val F1 = 0.8176, Time = 61.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:12<00:00, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive_bayes: Val Accuracy = 0.7500, Val F1 = 0.7512, Time = 0.26s\n",
      "\n",
      "STEP 3: Hyperparameter Optimization\n",
      "----------------------------------------------------------------------\n",
      "Starting hyperparameter optimization...\n",
      "Optimizing random_forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/backend/popen_loky_posix.py\", line 180, in <module>\n",
      "    exitcode = process_obj._bootstrap()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 453, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/backend/popen_loky_posix.py\", line 180, in <module>\n",
      "    exitcode = process_obj._bootstrap()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 453, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/backend/popen_loky_posix.py\", line 180, in <module>\n",
      "    exitcode = process_obj._bootstrap()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 453, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/backend/popen_loky_posix.py\", line 180, in <module>\n",
      "    exitcode = process_obj._bootstrap()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 453, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/backend/popen_loky_posix.py\", line 180, in <module>\n",
      "    exitcode = process_obj._bootstrap()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 453, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/backend/popen_loky_posix.py\", line 180, in <module>\n",
      "    exitcode = process_obj._bootstrap()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 453, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/backend/popen_loky_posix.py\", line 180, in <module>\n",
      "    exitcode = process_obj._bootstrap()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 453, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/backend/popen_loky_posix.py\", line 180, in <module>\n",
      "    exitcode = process_obj._bootstrap()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 453, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/backend/popen_loky_posix.py\", line 180, in <module>\n",
      "    exitcode = process_obj._bootstrap()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 453, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/backend/popen_loky_posix.py\", line 180, in <module>\n",
      "    exitcode = process_obj._bootstrap()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 453, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/backend/popen_loky_posix.py\", line 180, in <module>\n",
      "    exitcode = process_obj._bootstrap()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 453, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/backend/popen_loky_posix.py\", line 180, in <module>\n",
      "    exitcode = process_obj._bootstrap()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 453, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/backend/popen_loky_posix.py\", line 180, in <module>\n",
      "    exitcode = process_obj._bootstrap()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 453, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/backend/popen_loky_posix.py\", line 180, in <module>\n",
      "    exitcode = process_obj._bootstrap()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 453, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/backend/popen_loky_posix.py\", line 180, in <module>\n",
      "    exitcode = process_obj._bootstrap()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 453, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/backend/popen_loky_posix.py\", line 180, in <module>\n",
      "    exitcode = process_obj._bootstrap()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 453, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/ghost/anaconda3/envs/fake_news/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/ghost/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 453, in _process_worker\n    call_item = call_queue.get(block=True, timeout=timeout)\n  File \"/home/ghost/anaconda3/envs/fake_news/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n    return _ForkingPickler.loads(res)\nAttributeError: Can't get attribute 'RankWarning' on <module 'numpy' from '/home/ghost/.local/lib/python3.10/site-packages/numpy/__init__.py'>\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Run quick training\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mquick_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining complete! Access results with:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - results[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] - All trained models\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m, in \u001b[0;36mquick_train\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m CompletePipeline()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Run with default settings (no BERT for speed)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_complete_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_bert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set to True if you have GPU and time\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_deep_nn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "Cell \u001b[0;32mIn[12], line 40\u001b[0m, in \u001b[0;36mCompletePipeline.run_complete_pipeline\u001b[0;34m(self, train_bert, train_deep_nn)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSTEP 3: Hyperparameter Optimization\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m optimized_models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraditional_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameter_optimization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_models\u001b[38;5;241m.\u001b[39mupdate({name: info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m name, info \u001b[38;5;129;01min\u001b[39;00m optimized_models\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Step 4: Create ensemble\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 114\u001b[0m, in \u001b[0;36mTraditionalMLTrainer.hyperparameter_optimization\u001b[0;34m(self, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Use RandomizedSearchCV for efficiency\u001b[39;00m\n\u001b[1;32m    104\u001b[0m search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m    105\u001b[0m     base_model, \n\u001b[1;32m    106\u001b[0m     param_grid, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    112\u001b[0m )\n\u001b[0;32m--> 114\u001b[0m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Evaluate best model\u001b[39;00m\n\u001b[1;32m    117\u001b[0m best_model \u001b[38;5;241m=\u001b[39m search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m ):\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1046\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1047\u001b[0m     )\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1051\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1992\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1991\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1992\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1994\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1995\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1996\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:997\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    993\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    994\u001b[0m         )\n\u001b[1;32m    995\u001b[0m     )\n\u001b[0;32m--> 997\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1017\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1020\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[1;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     75\u001b[0m     (\n\u001b[1;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     81\u001b[0m )\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1784\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m     nb_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1859\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1859\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:758\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    752\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:773\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 773\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable."
     ]
    }
   ],
   "source": [
    "## 10. Usage Instructions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FAKE NEWS DETECTION MODEL TRAINING\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nAvailable training options:\")\n",
    "    print(\"\\n1. Quick Training (Recommended):\")\n",
    "    print(\"   results = quick_train()\")\n",
    "    print(\"\\n2. Complete Pipeline:\")\n",
    "    print(\"   pipeline = CompletePipeline()\")\n",
    "    print(\"   results = pipeline.run_complete_pipeline(train_bert=False, train_deep_nn=True)\")\n",
    "    print(\"\\n3. Single Model Training:\")\n",
    "    print(\"   model, metrics, path = train_single_model('random_forest')\")\n",
    "    print(\"\\n4. Custom Training:\")\n",
    "    print(\"   # Use individual trainer classes for custom workflows\")\n",
    "    print(\"\\nStarting quick training...\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Run quick training\n",
    "    results = quick_train()\n",
    "    \n",
    "    print(\"\\nTraining complete! Access results with:\")\n",
    "    print(\"  - results['models'] - All trained models\")\n",
    "    print(\"  - results['test_results'] - Test set evaluation\")\n",
    "    print(\"  - results['comparison'] - Model comparison dataframe\")\n",
    "    print(\"  - results['best_model_path'] - Path to best model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb43778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake_news",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
